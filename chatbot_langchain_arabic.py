import streamlit as st
from PIL import Image
import json
from datetime import datetime
from shared.config import init_apis, TEXT_MODEL
from shared.langchain_rag import init_langchain_rag
from shared.embeddings import get_image_description, get_image_category
from shared.database import search_by_image  # Keep for image search
import openai

# Page config
st.set_page_config(
    page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ¬Ø± Ø§Ù„Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª",
    page_icon="ğŸ’",
    layout="wide"
)

# Add RTL CSS and chat input positioning
st.markdown("""
<style>
    .main .block-container {
        direction: rtl;
        text-align: right;
        padding-bottom: 100px;
    }
    .stChatMessage {
        direction: rtl;
        text-align: right;
    }
    .stTextInput > div > div > input {
        direction: rtl;
        text-align: right;
    }
    .stFileUploader > div {
        direction: rtl;
        text-align: right;
    }
    h1 {
        direction: rtl;
        text-align: right;
    }
    .stRadio {
        direction: rtl !important;
        text-align: right !important;
    }
    .stRadio > div[role="radiogroup"] {
        direction: rtl !important;
        justify-content: flex-end !important;
        display: flex !important;
        flex-direction: row-reverse !important;
    }
    .stRadio > div[role="radiogroup"] > label {
        direction: rtl !important;
        margin-left: 1rem !important;
        margin-right: 0 !important;
    }
    .stRadio div[data-testid="stHorizontalBlock"] {
        direction: rtl !important;
        justify-content: flex-end !important;
    }
    .stChatInputContainer {
        position: fixed;
        bottom: 0;
        left: 0;
        right: 0;
        background: white;
        z-index: 1000;
        padding: 10px 20px;
        border-top: 1px solid #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Add initial assistant message
    st.session_state.messages.append({
        "role": "assistant",
        "content": "Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ"
    })

if "rag_system" not in st.session_state:
    st.session_state.rag_system = None

if "active_tab" not in st.session_state:
    st.session_state.active_tab = "chat"



# Initialize APIs and RAG
try:
    openai_client, pinecone_index = init_apis()

    # Initialize LangChain RAG system
    if st.session_state.rag_system is None:
        with st.spinner("ØªØ­Ø¶ÙŠØ± Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ..."):
            st.session_state.rag_system = init_langchain_rag(
                pinecone_index,
                st.secrets["OPENAI_API_KEY"]
            )

        if not st.session_state.rag_system:
            st.error("âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­Ø«")
            st.stop()

except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    st.stop()

st.title("ğŸ’ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ¬Ø± Ø§Ù„Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª")

def is_product_query(message: str) -> bool:
    """
    More precise detection of product queries
    Only search when user is clearly looking for products
    """
    message_lower = message.lower()

    # Explicit product requests - these should definitely trigger search
    explicit_requests = [
        "Ø£Ø±ÙŠØ¯", "Ø§Ø¨Ø­Ø«", "Ø¹Ù†Ø¯ÙƒÙ†", "Ø¹Ù†Ø¯ÙƒÙ…", "Ù…ØªÙˆÙØ±", "Ù…ÙˆØ¬ÙˆØ¯", "Ù„Ø¯ÙŠÙƒÙ…", "Ù„Ø¯ÙŠÙƒÙ†",
        "Ø§Ø¹Ø±Ø¶", "Ø£Ø¹Ø±Ø¶", "ÙˆØ±ÙŠÙ†ÙŠ", "Ø£ÙˆØ±ÙŠÙ†ÙŠ", "Ø§Ø·Ù„Ø¨", "Ø£Ø·Ù„Ø¨"
    ]

    # Product names - only search if mentioned
    product_names = [
        "Ø®Ø§ØªÙ…", "Ø®ÙˆØ§ØªÙ…", "Ø¹Ù‚Ø¯", "Ø¹Ù‚ÙˆØ¯", "Ù‚Ù„Ø§Ø¯Ø©", "Ù‚Ù„Ø§Ø¦Ø¯",
        "Ø³Ù„Ø³Ù„Ø©", "Ø³Ù„Ø§Ø³Ù„", "Ø³Ù„Ø³Ø§Ù„", "Ø£Ù‚Ø±Ø§Ø·", "Ù‚Ø±Ø·",
        "Ø³ÙˆØ§Ø±", "Ø£Ø³Ø§ÙˆØ±", "Ø§Ø³ÙˆØ±Ø©", "Ø¯Ø¨ÙˆØ³", "Ø¯Ø¨Ø§Ø¨ÙŠØ³", "Ø·Ù‚Ù…", "Ø£Ø·Ù‚Ù…"
    ]

    # Materials with intent words
    material_queries = [
        "Ø°Ù‡Ø¨", "Ø°Ù‡Ø¨ÙŠ", "Ø°Ù‡Ø¨ÙŠØ©", "ÙØ¶Ø©", "ÙØ¶ÙŠ", "ÙØ¶ÙŠØ©",
        "Ù…Ø§Ø³", "Ø£Ù„Ù…Ø§Ø³", "Ù„Ø¤Ù„Ø¤"
    ]

    # Check for explicit requests
    has_explicit_request = any(req in message_lower for req in explicit_requests)

    # Check for product names
    has_product_name = any(product in message_lower for product in product_names)

    # Check for material queries with some context
    has_material_context = any(material in message_lower for material in material_queries)

    # Product questions with question words
    question_indicators = ["Ù…Ø§ Ø§Ù„Ù…ØªÙˆÙØ±", "Ù…Ø§Ø°Ø§ Ø¹Ù†Ø¯ÙƒÙ…", "Ù…Ø§Ø°Ø§ Ù„Ø¯ÙŠÙƒÙ…", "Ù…Ø§ Ø¹Ù†Ø¯ÙƒÙ†", "Ù…Ø§ Ù„Ø¯ÙŠÙƒÙ†"]
    has_product_question = any(q in message_lower for q in question_indicators)

    # Only trigger search if:
    # 1. Explicit request OR
    # 2. Product name mentioned OR
    # 3. Material mentioned with some context OR
    # 4. Specific product question
    return (has_explicit_request or
            has_product_name or
            (has_material_context and len(message.split()) > 2) or
            has_product_question)

def get_general_response(prompt: str) -> str:
    """Handle general conversation that doesn't require product search"""
    try:
        response = openai.chat.completions.create(
            model=TEXT_MODEL,
            messages=[
                {"role": "system", "content": """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ Ù„Ù…ØªØ¬Ø± Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª.

                Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª (ÙƒØ§Ù„Ø¹Ù†Ø§ÙŠØ©ØŒ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø§ØªØŒ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹)ØŒ Ù‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ù…ÙÙŠØ¯Ø©.
                Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø¹Ù† Ù…Ù†ØªØ¬Ø§Øª Ù…Ø­Ø¯Ø¯Ø©ØŒ Ø§Ù†ØµØ­ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ø£Ù† ÙŠØ³Ø£Ù„ Ø¹Ù† Ù…Ù†ØªØ¬Ø§Øª Ù…Ø¹ÙŠÙ†Ø© Ù„ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ø®Ø²ÙˆÙ†Ù†Ø§.

                ÙƒÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆØªØ­Ø¯Ø« Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."""},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}"

def display_products(products):
    """Display product results in a nice format"""
    if not products:
        return

    cols = st.columns(min(len(products), 3))
    for idx, result in enumerate(products):
        with cols[idx % 3]:
            metadata = result['metadata']

            with st.container():
                st.markdown(f"**{metadata.get('name', 'Ù…Ù†ØªØ¬')}**")
                st.markdown(f"ğŸ’° **{metadata.get('price', 0):.2f} Ø±ÙŠØ§Ù„**")
                st.markdown(f"ğŸ“‚ {metadata.get('category', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")

                # Show additional details
                details = []
                if metadata.get('karat'):
                    details.append(f"Ø§Ù„Ø¹ÙŠØ§Ø±: {metadata.get('karat')}")
                if metadata.get('weight', 0) > 0:
                    details.append(f"Ø§Ù„ÙˆØ²Ù†: {metadata.get('weight')} Ø¬Ø±Ø§Ù…")
                if metadata.get('design'):
                    details.append(f"Ø§Ù„ØªØµÙ…ÙŠÙ…: {metadata.get('design')}")

                if details:
                    st.markdown(f"ğŸ”¹ {' | '.join(details)}")

                # Description (truncated)
                description = metadata.get('description', '')
                if len(description) > 100:
                    description = description[:100] + "..."
                st.markdown(f"ğŸ“ {description}")

                # Match score
                if 'score' in result:
                    st.markdown(f"ğŸ¯ ØªØ·Ø§Ø¨Ù‚: {result['score'] * 100:.1f}%")

                # Add to cart button
                if st.button(f"ğŸ›’ Ø£Ø¶Ù Ù„Ù„Ø³Ù„Ø©", key=f"cart_{result['id']}_{idx}"):
                    st.success("ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ù„Ø³Ù„Ø©! ğŸ›ï¸")

                st.markdown("---")

# Tab selection with radio buttons - using columns to align right
col1, col2 = st.columns([3, 1])

with col2:
    tab_choice = st.radio(
        "Ø§Ø®ØªØ± Ø§Ù„Ù†Ø´Ø§Ø·:",
        ["ğŸ“¸ Ø¨Ø­Ø« Ø¨Ø§Ù„ØµÙˆØ±Ø©", "ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ©"],
        horizontal=True,
        index=1  # Default to "Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ©" (text search)
    )

st.session_state.active_tab = "chat" if "Ù…Ø­Ø§Ø¯Ø«Ø©" in tab_choice else "image"

if st.session_state.active_tab == "chat":
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

elif st.session_state.active_tab == "image":
    # Image upload section
    uploaded_image = st.file_uploader(
        "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù‚Ø·Ø¹Ø© Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª:",
        type=['png', 'jpg', 'jpeg'],
        help="ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ ØµÙˆØ±Ø© Ù‚Ø·Ø¹Ø© Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª Ù„Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù†Ù‡Ø§ Ø£Ùˆ Ø£Ø¬Ø¯ Ù‚Ø·Ø¹ Ù…Ø´Ø§Ø¨Ù‡Ø©"
    )

    if uploaded_image:
        image = Image.open(uploaded_image)
        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", width=300)

        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø¨Ø­Ø« Ø¹Ù† Ù…Ø´Ø§Ø¨Ù‡Ø©", type="primary"):
            with st.spinner("ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ø¨Ø­Ø«..."):
                # Analyze the image
                description = get_image_description(image)
                category = get_image_category(image)

                # Search for similar products using traditional image search
                search_results = search_by_image(pinecone_index, image, top_k=5)

                # Convert results to our format for display
                formatted_results = []
                if search_results:
                    for result in search_results:
                        formatted_results.append({
                            'id': result.id,
                            'score': result.score,
                            'metadata': result.metadata
                        })

                # Generate response using RAG
                analysis_query = f"Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©: {description}. Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {category}"
                if st.session_state.rag_system:
                    bot_response, _ = st.session_state.rag_system.conversational_search(
                        analysis_query
                    )
                else:
                    bot_response = f"ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {description}\nØ§Ù„ÙØ¦Ø©: {category}"

                # Display results
                st.markdown(bot_response)

                if formatted_results:
                    display_products(formatted_results)
                else:
                    st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù†ØªØ¬Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©")

                # Add to chat history
                st.session_state.messages.append({
                    "role": "user",
                    "content": "ğŸ–¼ï¸ Ø±ÙØ¹Øª ØµÙˆØ±Ø© Ù‚Ø·Ø¹Ø© Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª"
                })
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": bot_response,
                    "products": formatted_results if formatted_results else None
                })
    else:
        st.info("Ø§Ø®ØªØ± ØµÙˆØ±Ø©")

# Chat input - only show on chat tab
if st.session_state.active_tab == "chat":
    if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§..."):
        # Display user message immediately
        with st.chat_message("user"):
            st.markdown(prompt)

        # Display assistant thinking and response
        with st.chat_message("assistant"):
            thinking_placeholder = st.empty()
            thinking_placeholder.markdown("ğŸ¤” Ø£ÙÙƒØ±...")

            if st.session_state.rag_system and is_product_query(prompt):
                response, search_results = st.session_state.rag_system.conversational_search(
                    prompt,
                    conversation_history=st.session_state.messages
                )
            else:
                response = get_general_response(prompt)

            thinking_placeholder.markdown(response)

        # Add to history after display
        st.session_state.messages.extend([
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": response}
        ])

